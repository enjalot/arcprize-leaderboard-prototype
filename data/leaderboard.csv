Config,Provider,Display_Name,Model_Type,Model_Group,Paper_URL,Code_URL,Data_URL,display,Model_Release_Date,v2_Public_Eval_Score,v2_Public_Eval_Cost_Per_Task,v2_Semi_Private_Score,v2_Semi_Private_Cost_Per_Task,v2_Private_Eval_Score,v2_Private_Eval_Cost_Per_Task,v1_Public_Eval_Score,v1_Public_Eval_Cost_Per_Task,v1_Semi_Private_Score,v1_Semi_Private_Cost_Per_Task,v1_Private_Eval_Score,v1_Private_Eval_Cost_Per_Task
2025_human_panel,Human,Human Panel,,Human,,,,true,,1.00,17,1.00,17,1.00,17,,,0.980,17,,
ARChitects,ARC Prize 2024,ARChitects,Custom,Kaggle,https://github.com/da-fr/arc-prize-2024/blob/main/the_architects.pdf,https://www.kaggle.com/code/gregkamradt/arc-prize-v8?scriptVersionId=211457842,,true,2024-11-03,0.035,0.200,0.025,0.200,0.031,0.200,,,0.560,0.200,,
Claude 3.7,Anthropic,Claude 3.7,Base LLM,,,https://github.com/arcprize/model_baseline,,true,2025-02-24,0.000,0.120,0.000,0.120,,,,,0.136,0.058,,
Claude 3.7 Thinking 16K,Anthropic,Claude 3.7 (16K),CoT,Claude_3_7_thinking,,https://github.com/arcprize/model_baseline,,true,2025-02-24,0.008,0.570,0.007,0.510,,,,,0.286,0.330,,
Claude 3.7 Thinking 1K,Anthropic,Claude 3.7 (1K),CoT,Claude_3_7_thinking,,https://github.com/arcprize/model_baseline,,true,2025-02-24,0.008,0.140,0.004,0.140,,,,,0.116,0.070,,
Claude 3.7 Thinking 8K,Anthropic,Claude 3.7 (8K),CoT,Claude_3_7_thinking,,https://github.com/arcprize/model_baseline,,true,2025-02-24,0.000,0.360,0.009,0.360,,,,,0.212,0.210,,
Gemini 1.5 Pro,Google,Gemini 1.5 Pro,Base LLM,,,https://github.com/arcprize/model_baseline,,true,2025-02-15,0.000,0.040,0.008,0.040,,,,,,,,
Gemini 2.0 Flash,Google,Gemini 2.0 Flash,Base LLM,,,https://github.com/arcprize/model_baseline,,true,2025-02-02,0.000,0.000,0.013,0.004,,,,,,,,
gpt-4.5-preview-2025-02-27,OpenAI,GPT-4.5,Base LLM,,,https://github.com/arcprize/model_baseline,,true,2025-02-27,0.000,2.070,0.008,2.100,,,,,0.103,0.290,,
gpt-4o-2024-11-20,OpenAI,GPT-4o,Base LLM,,,https://github.com/arcprize/model_baseline,,true,2024-11-20,0.000,0.080,0.000,0.080,,,,,4.500,0.050,,
gpt-4o-mini-2024-07-18,OpenAI,GPT-4o-mini,Base LLM,,,https://github.com/arcprize/model_baseline,,true,2024-07-18,0.000,0.010,0.000,0.010,,,,,,,,
Grok 3,xAI,Grok 3,Base LLM,,,,,true,2025-02-13,,,,,,,,,,,,
Grok 3 Thinking,xAI,Grok 3 Thinking,CoT,,,,,true,2025-02-13,,,,,,,,,,,,
Icecuber,ARC Prize 2024,Icecuber,Custom,Kaggle,,https://www.kaggle.com/code/hansuelijud/template-arc2020-1st-place-solution-by-icecuber,,true,2023-11-03,0.029,0.130,0.016,0.130,0.004,0.130,,,0.17,0.200,,
Llama 3.3,Meta,Llama 3.3,Base LLM,,,,,true,2024-12-06,,,,,,,,,,,,
mturker,Human,Avg. Mturker,,Human,,,,true,,,,,,,,,,0.770,3,,
o1 - high,OpenAI,o1 (high),CoT,o1,,https://github.com/arcprize/model_baseline,,true,2024-12-05,0.000,4.850,0.030,4.450,,,,,0.320,3.800,,
o1 - low,OpenAI,o1 (low),CoT,o1,,https://github.com/arcprize/model_baseline,,true,2024-12-05,0.000,1.480,0.008,1.440,,,,,0.250,1.500,,
o1 - medium,OpenAI,o1 (medium),CoT,o1,,https://github.com/arcprize/model_baseline,,true,2024-12-05,0.000,2.700,0.013,2.760,,,,,0.310,2.500,,
o1-pro,OpenAI,o1-pro,CoT + Synthesis,o1-pro,,,,true,2024-12-05,0.010,39,0.010,39,,,,,.5,39,,
o3-low,OpenAI,o3 (low)*,CoT + Synthesis,o3,https://arcprize.org/blog/oai-o3-pub-breakthrough,,,true,2024-12-20,,,0.040,200,,,,,0.757,200,,
o3-high,OpenAI,o3 (high),CoT + Synthesis,o3,https://arcprize.org/blog/oai-o3-pub-breakthrough,,,false,2024-12-20,,,0.15,3474,,,,,0.875,3474.000,,
o3-mini-high,OpenAI,o3-mini (high),CoT,o3-mini,,https://github.com/arcprize/model_baseline,,true,2025-01-31,0.000,0.490,0.015,0.410,,,,,0.350,0.190,,
o3-mini-medium,OpenAI,o3-mini (medium),CoT,o3-mini,,https://github.com/arcprize/model_baseline,,true,2025-01-31,0.000,0.280,0.017,0.280,,,,,0.291,0.090,,
o3-mini-low,OpenAI,o3-mini (low),CoT,o3-mini,,https://github.com/arcprize/model_baseline,,true,2025-01-31,0.000,0.060,0.000,0.060,,,,,0.110,0.040,,
R1,Deepseek,Deepseek R1,CoT,,,https://github.com/arcprize/model_baseline,,true,2025-01-22,0.003,0.080,0.013,0.080,,,,,0.158,0.060,,
stem_grad,Human,Stem Grad,,Human,,,,true,,,,,,,,,,0.980,10.000,,
gemini-2.5-pro-exp-03-25,Google,Gemini-2.5-Pro-Exp-03-25 **,CoT,,,https://github.com/arcprize/model_baseline,,false,2025-03-25,0.0083,-,0.0125,-,,,0.2425,-,0.125,-,,
Llama-4-Maverick-17B-128E-Instruct-FP8-together,Meta,Llama 4 Maverick,Base LLM,Llama 4,https://www.llama.com/docs/model-cards-and-prompt-formats/llama4_omni/,https://github.com/arcprize/model_baseline,,true,2025-04-05,0.000,0.0126,0.000,0.0121,,,0.0712,0.0065,0.0438,0.0078,,
Llama-4-Scout-17B-16E-Instruct-together,Meta,Llama 4 Scout,Base LLM,Llama 4,https://www.llama.com/docs/model-cards-and-prompt-formats/llama4_omni/,https://github.com/arcprize/model_baseline,,true,2025-04-05,0.000,0.006,0.000,0.0062,,,0.0238,0.0036,0.005,0.0041,,